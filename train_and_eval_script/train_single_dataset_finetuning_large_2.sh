# refcoco
echo -e "\n\n\n\n\n\n\n==================== unc warmup ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs  60 --batch_size 32 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate   --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc      --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --retrain /patch_to_output/output_v100_warm/unc/best_checkpoint.pth  --output_dir /patch_to_output/output_v100/unc --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc/best_checkpoint.pth --eval_set val      --output_dir /patch_to_output/output_v100/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc/best_checkpoint.pth --eval_set testA    --output_dir /patch_to_output/output_v100/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc/best_checkpoint.pth --eval_set testB    --output_dir /patch_to_output/output_v100/unc;
##
# stage 1
echo -e "\n\n\n\n\n\n\n==================== unc stage 1 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00010   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc      --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v100/unc/best_checkpoint.pth      --hi_lora_clip /patch_to_output/output_v100/unc/clip_lora_stage_with_bridge.pth       --output_dir /patch_to_output/output_v101/unc      --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc/best_checkpoint.pth      --eval_set val    --output_dir /patch_to_output/output_v101/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc/best_checkpoint.pth      --eval_set testA  --output_dir /patch_to_output/output_v101/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc/best_checkpoint.pth      --eval_set testB  --output_dir /patch_to_output/output_v101/unc;
#
# stage 2
echo -e "\n\n\n\n\n\n\n==================== unc stage 2 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00005   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc      --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v101/unc/best_checkpoint.pth      --hi_lora_clip /patch_to_output/output_v101/unc/clip_lora_stage_with_bridge.pth       --output_dir /patch_to_output/output_v102/unc      --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc/best_checkpoint.pth      --eval_set val    --output_dir /patch_to_output/output_v102/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc/best_checkpoint.pth      --eval_set testA  --output_dir /patch_to_output/output_v102/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc/best_checkpoint.pth      --eval_set testB  --output_dir /patch_to_output/output_v102/unc;
#
# stage 3
echo -e "\n\n\n\n\n\n\n==================== unc stage 3 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.000025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc      --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v102/unc/best_checkpoint.pth      --hi_lora_clip /patch_to_output/output_v102/unc/clip_lora_stage_with_bridge.pth       --output_dir /patch_to_output/output_v103/unc      --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc/best_checkpoint.pth      --eval_set val    --output_dir /patch_to_output/output_v103/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc/best_checkpoint.pth      --eval_set testA  --output_dir /patch_to_output/output_v103/unc;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc           --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc/best_checkpoint.pth      --eval_set testB  --output_dir /patch_to_output/output_v103/unc;
#

## # RefCOCO+
echo -e "\n\n\n\n\n\n\n==================== unc+ warmup ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs  60 --batch_size 32 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate   --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc+     --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --retrain /patch_to_output/output_v100_warm/unc+/best_checkpoint.pth  --output_dir /patch_to_output/output_v100/unc+ --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc+/best_checkpoint.pth --eval_set val      --output_dir /patch_to_output/output_v100/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc+/best_checkpoint.pth --eval_set testA    --output_dir /patch_to_output/output_v100/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/unc+/best_checkpoint.pth --eval_set testB    --output_dir /patch_to_output/output_v100/unc+;
##
# stage 1
echo -e "\n\n\n\n\n\n\n==================== unc+ stage 1 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00010   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc+     --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v100/unc+/best_checkpoint.pth     --hi_lora_clip /patch_to_output/output_v100/unc+/clip_lora_stage_with_bridge.pth      --output_dir /patch_to_output/output_v101/unc+     --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc+/best_checkpoint.pth     --eval_set val    --output_dir /patch_to_output/output_v101/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc+/best_checkpoint.pth     --eval_set testA  --output_dir /patch_to_output/output_v101/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/unc+/best_checkpoint.pth     --eval_set testB  --output_dir /patch_to_output/output_v101/unc+;
# stage 2
echo -e "\n\n\n\n\n\n\n==================== unc+ stage 2 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00005   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc+     --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v101/unc+/best_checkpoint.pth     --hi_lora_clip /patch_to_output/output_v101/unc+/clip_lora_stage_with_bridge.pth      --output_dir /patch_to_output/output_v102/unc+     --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc+/best_checkpoint.pth     --eval_set val    --output_dir /patch_to_output/output_v102/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc+/best_checkpoint.pth     --eval_set testA  --output_dir /patch_to_output/output_v102/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/unc+/best_checkpoint.pth     --eval_set testB  --output_dir /patch_to_output/output_v102/unc+;
# stage 3
echo -e "\n\n\n\n\n\n\n==================== unc+ stage 3 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.000025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset unc+     --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v102/unc+/best_checkpoint.pth     --hi_lora_clip /patch_to_output/output_v102/unc+/clip_lora_stage_with_bridge.pth      --output_dir /patch_to_output/output_v103/unc+     --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc+/best_checkpoint.pth     --eval_set val    --output_dir /patch_to_output/output_v103/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc+/best_checkpoint.pth     --eval_set testA  --output_dir /patch_to_output/output_v103/unc+;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset unc+          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/unc+/best_checkpoint.pth     --eval_set testB  --output_dir /patch_to_output/output_v103/unc+;


## gref_umd
echo -e "\n\n\n\n\n\n\n==================== gref_umd warmup ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs  60 --batch_size 32 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate   --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset gref_umd --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --retrain /patch_to_output/output_v100_warm/gref_umd/best_checkpoint.pth   --output_dir /patch_to_output/output_v100/gref_umd --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset gref          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v100/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v100/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/gref_umd/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v100/gref_umd;
##
## stage 1
echo -e "\n\n\n\n\n\n\n==================== gref_umd stage 1 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00010   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset gref_umd --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v100/gref_umd/best_checkpoint.pth --hi_lora_clip /patch_to_output/output_v100/gref_umd/clip_lora_stage_with_bridge.pth  --output_dir /patch_to_output/output_v101/gref_umd --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v101/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v101/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/gref_umd/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v101/gref_umd;
##
# stage 2
echo -e "\n\n\n\n\n\n\n==================== gref_umd stage 2 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00005   --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset gref_umd --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v101/gref_umd/best_checkpoint.pth --hi_lora_clip /patch_to_output/output_v101/gref_umd/clip_lora_stage_with_bridge.pth  --output_dir /patch_to_output/output_v102/gref_umd --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v102/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v102/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/gref_umd/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v102/gref_umd;
##
# stage 3
echo -e "\n\n\n\n\n\n\n==================== gref_umd stage 3 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.000025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset gref_umd --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v102/gref_umd/best_checkpoint.pth --hi_lora_clip /patch_to_output/output_v102/gref_umd/clip_lora_stage_with_bridge.pth  --output_dir /patch_to_output/output_v103/gref_umd --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref          --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v103/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/gref_umd/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v103/gref_umd;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset gref_umd      --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/gref_umd/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v103/gref_umd;
##
#
# Referit
echo -e "\n\n\n\n\n\n\n==================== referit warmup ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs  60 --batch_size 32 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate   --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset referit --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --retrain /patch_to_output/output_v100_warm/referit/best_checkpoint.pth  --output_dir /patch_to_output/output_v100/referit --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/referit/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v100/referit;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/referit/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v100/referit;
# stage 1
echo -e "\n\n\n\n\n\n\n==================== referit stage 1 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00010  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset referit  --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v100/referit/best_checkpoint.pth  --hi_lora_clip /patch_to_output/output_v100/referit/clip_lora_stage_with_bridge.pth   --output_dir /patch_to_output/output_v101/referit  --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/referit/best_checkpoint.pth  --eval_set val    --output_dir /patch_to_output/output_v101/referit;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/referit/best_checkpoint.pth  --eval_set test   --output_dir /patch_to_output/output_v101/referit;
##
# stage 2
echo -e "\n\n\n\n\n\n\n==================== referit stage 2 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.00005  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset referit  --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v101/referit/best_checkpoint.pth  --hi_lora_clip /patch_to_output/output_v101/referit/clip_lora_stage_with_bridge.pth   --output_dir /patch_to_output/output_v102/referit  --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/referit/best_checkpoint.pth  --eval_set val    --output_dir /patch_to_output/output_v102/referit;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/referit/best_checkpoint.pth  --eval_set test   --output_dir /patch_to_output/output_v102/referit;
# stage 3
echo -e "\n\n\n\n\n\n\n==================== referit stage 3 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 10  --batch_size 32 --lr 0.000025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset referit  --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v102/referit/best_checkpoint.pth  --hi_lora_clip /patch_to_output/output_v102/referit/clip_lora_stage_with_bridge.pth   --output_dir /patch_to_output/output_v103/referit  --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/referit/best_checkpoint.pth  --eval_set val    --output_dir /patch_to_output/output_v103/referit;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset referit       --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/referit/best_checkpoint.pth  --eval_set test   --output_dir /patch_to_output/output_v103/referit;
##

# Flickr
echo -e "\n\n\n\n\n\n\n==================== flickr warmup ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 30 --batch_size 32 --lr 0.00025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate   --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset flickr   --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --retrain /patch_to_output/output_v100_warm/flickr/best_checkpoint.pth  --output_dir /patch_to_output/output_v100/flickr --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/flickr/best_checkpoint.pth --eval_set val    --output_dir /patch_to_output/output_v100/flickr;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss --save_hilora_clip --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v100/flickr/best_checkpoint.pth --eval_set test   --output_dir /patch_to_output/output_v100/flickr;
# stage 1
echo -e "\n\n\n\n\n\n\n==================== flickr stage 1 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 5  --batch_size 32 --lr 0.00010  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset flickr   --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v100/flickr/best_checkpoint.pth   --hi_lora_clip /patch_to_output/output_v100/flickr/clip_lora_stage_with_bridge.pth    --output_dir /patch_to_output/output_v101/flickr   --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/flickr/best_checkpoint.pth   --eval_set val    --output_dir /patch_to_output/output_v101/flickr;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 1 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v101/flickr/best_checkpoint.pth   --eval_set test   --output_dir /patch_to_output/output_v101/flickr;
##
### stage 2
echo -e "\n\n\n\n\n\n\n==================== flickr stage 2 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 5  --batch_size 32 --lr 0.00005  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset flickr   --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v101/flickr/best_checkpoint.pth   --hi_lora_clip /patch_to_output/output_v101/flickr/clip_lora_stage_with_bridge.pth    --output_dir /patch_to_output/output_v102/flickr   --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/flickr/best_checkpoint.pth   --eval_set val    --output_dir /patch_to_output/output_v102/flickr;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 2 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v102/flickr/best_checkpoint.pth   --eval_set test   --output_dir /patch_to_output/output_v102/flickr;
##
# stage 3
echo -e "\n\n\n\n\n\n\n==================== flickr stage 3 ==========================="
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28887 --use_env hivg_train.py --num_workers 4 --epochs 5  --batch_size 32 --lr 0.000025  --lr_scheduler cosine --aug_crop --aug_scale --aug_translate  --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --model ViT-L/14  --dataset flickr   --use_contrastive_loss  --use_rtcc_constrain_loss --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data  --split_root /path_to_split/ref_data_shuffled --hi_lora_retrain /patch_to_output/output_v102/flickr/best_checkpoint.pth   --hi_lora_clip /patch_to_output/output_v102/flickr/clip_lora_stage_with_bridge.pth    --output_dir /patch_to_output/output_v103/flickr   --sup_type full;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/flickr/best_checkpoint.pth   --eval_set val    --output_dir /patch_to_output/output_v103/flickr;
CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 python -m torch.distributed.launch --nproc_per_node=7 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 32  --model ViT-L/14  --dataset flickr        --vl_hidden_dim 768 --imsize 224 --max_query_len 77 --normalize_before --enable_adaptive_weights --use_mask_loss  --save_hilora_clip --hi_lora_stage 3 --data_root /path_to_image_data --split_root /path_to_split/ref_data_shuffled --eval_model /patch_to_output/output_v103/flickr/best_checkpoint.pth   --eval_set test   --output_dir /patch_to_output/output_v103/flickr;
##





