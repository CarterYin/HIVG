

CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc           --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to_output/mixup_pretraining_base/unc;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc           --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set testA  --output_dir /path_to_output/mixup_pretraining_base/unc;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc           --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set testB  --output_dir /path_to_output/mixup_pretraining_base/unc;
#

#
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc+          --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to_output/mixup_pretraining_base/unc+;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc+          --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set testA  --output_dir /path_to_output/mixup_pretraining_base/unc+;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset unc+          --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set testB  --output_dir /path_to_output/mixup_pretraining_base/unc+;

#
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset gref_umd      --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to_output/mixup_pretraining_base/gref_umd;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset gref_umd      --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set test   --output_dir /path_to_output/mixup_pretraining_base/gref_umd;
##

CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset referit       --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to_output/mixup_pretraining_base/referit;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset referit       --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set test   --output_dir /path_to_output/mixup_pretraining_base/referit;
##
#
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset flickr        --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set val    --output_dir /path_to_output/mixup_pretraining_base/flickr;
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port 28888 --use_env hivg_eval.py --num_workers 2 --batch_size 64  --dataset flickr        --imsize 224 --max_query_len 77 --normalize_before --use_mask_loss  --hi_lora_stage 3 --save_hilora_clip --mixup_pretrain --data_root /patch_to_image_data --split_root /patch_to_split/ref_data_shuffled --eval_model /path_to_output/mixup_pretraining_base/mixup/best_checkpoint.pth --eval_set test   --output_dir /path_to_output/mixup_pretraining_base/flickr;
##
